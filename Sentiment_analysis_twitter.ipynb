{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment_analysis_twitter.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtotZDPUV5DN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import zipfile\n",
        "\n",
        "zip_ref = zipfile.ZipFile(\"/content/drive/My Drive/2477_4140_bundle_archive.zip\", 'r')\n",
        "zip_ref.extractall()\n",
        "zip_ref.close()"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JE9Mvdd9Bfw8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "outputId": "e7b1d4f8-fb60-4e63-822d-bc967a6350ed"
      },
      "source": [
        "pip install keras==2.2.4"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keras==2.2.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/10/aa32dad071ce52b5502266b5c659451cfd6ffcbf14e6c8c4f16c0ff5aaab/Keras-2.2.4-py2.py3-none-any.whl (312kB)\n",
            "\r\u001b[K     |█                               | 10kB 25.6MB/s eta 0:00:01\r\u001b[K     |██                              | 20kB 31.9MB/s eta 0:00:01\r\u001b[K     |███▏                            | 30kB 37.5MB/s eta 0:00:01\r\u001b[K     |████▏                           | 40kB 30.9MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 51kB 16.0MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 61kB 15.6MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 71kB 13.7MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 81kB 14.7MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 92kB 13.7MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 102kB 13.1MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 112kB 13.1MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 122kB 13.1MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 133kB 13.1MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 143kB 13.1MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 153kB 13.1MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 163kB 13.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 174kB 13.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 184kB 13.1MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 194kB 13.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 204kB 13.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 215kB 13.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 225kB 13.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 235kB 13.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 245kB 13.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 256kB 13.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 266kB 13.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 276kB 13.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 286kB 13.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 296kB 13.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 307kB 13.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 317kB 13.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.1.2)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.18.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (2.10.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.0.8)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.12.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (3.13)\n",
            "Installing collected packages: keras\n",
            "  Found existing installation: Keras 2.3.1\n",
            "    Uninstalling Keras-2.3.1:\n",
            "      Successfully uninstalled Keras-2.3.1\n",
            "Successfully installed keras-2.2.4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "keras"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWd2AAHcAxVG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "848a03cd-bc41-453a-e936-acbaf3e94153"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "keras.__version__"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'2.2.4'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7SpXhc7hVpdA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sys\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "import string\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import gensim\n",
        "import pickle\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM, Dropout\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.models import load_model\n",
        "from keras.callbacks import ReduceLROnPlateau, EarlyStopping"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MzmsiVURaZIe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "15a69818-43c7-40af-b50d-67f508e3baeb"
      },
      "source": [
        "nltk.download('punkt')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1x3vCnAYHYM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "4b2d8366-4805-47ef-9450-8679b7a05699"
      },
      "source": [
        "DATASET_COLUMNS = [\"target\", \"ids\", \"date\", \"flag\", \"user\", \"text\"]\n",
        "DATASET_ENCODING = \"ISO-8859-1\"\n",
        "data = pd.read_csv('/content/training.1600000.processed.noemoticon.csv', encoding =DATASET_ENCODING , names=DATASET_COLUMNS)\n",
        "data.head()\n",
        "X = data.iloc[:,[5]]\n",
        "Y = data.iloc[:,0]\n",
        "Y[Y == 4] = 1"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  import sys\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L7lCmXGkYHUO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "0127a1cc-5fb1-4a3b-f25d-1db87d166fc5"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>ids</th>\n",
              "      <th>date</th>\n",
              "      <th>flag</th>\n",
              "      <th>user</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810369</td>\n",
              "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>_TheSpecialOne_</td>\n",
              "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810672</td>\n",
              "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>scotthamilton</td>\n",
              "      <td>is upset that he can't update his Facebook by ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810917</td>\n",
              "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>mattycus</td>\n",
              "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811184</td>\n",
              "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>ElleCTF</td>\n",
              "      <td>my whole body feels itchy and like its on fire</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811193</td>\n",
              "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>Karoli</td>\n",
              "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   target  ...                                               text\n",
              "0       0  ...  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
              "1       0  ...  is upset that he can't update his Facebook by ...\n",
              "2       0  ...  @Kenichan I dived many times for the ball. Man...\n",
              "3       0  ...    my whole body feels itchy and like its on fire \n",
              "4       0  ...  @nationwideclass no, it's not behaving at all....\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eD5FoI2lhx8K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "fc60463f-bb2b-4f10-f5d3-a79283e0e9ff"
      },
      "source": [
        " nltk.download('stopwords')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZTuUwFRsxGt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "dc2528f9-a122-4286-af31-e6b276dc7463"
      },
      "source": [
        "nltk.download('wordnet')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rgUdMj4YHSY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "50e5d323-cafa-47c3-c82e-c254b3e1f4bb"
      },
      "source": [
        "# Text-preprocessing\n",
        "\n",
        "# Missing Values\n",
        "num_missing_desc = data.isnull().sum()[2]    # No. of values with msising descriptions\n",
        "print('Number of missing values: ' + str(num_missing_desc))\n",
        "data = data.dropna()\n",
        "\n",
        "TAG_CLEANING_RE = \"@\\S+\"\n",
        "# Remove @tags\n",
        "X['text'] = X['text'].map(lambda x: re.sub(TAG_CLEANING_RE, ' ', str(x)))\n",
        "\n",
        "# Smart lowercase\n",
        "X['text'] = X['text'].map(lambda x: x.lower())\n",
        "\n",
        "# Remove numbers\n",
        "X['text'] = X['text'].map(lambda x: re.sub(r'\\d+', ' ', x))\n",
        "\n",
        "# Remove links\n",
        "TEXT_CLEANING_RE = \"https?:\\S+|http?:\\S|[^A-Za-z0-9]+\"\n",
        "X['text'] = X['text'].map(lambda x: re.sub(TEXT_CLEANING_RE, ' ', x))\n",
        "\n",
        "# Remove Punctuation\n",
        "X['text']  = X['text'].map(lambda x: x.translate(x.maketrans('', '', string.punctuation)))\n",
        "\n",
        "# Remove white spaces\n",
        "X['text'] = X['text'].map(lambda x: x.strip())\n",
        "\n",
        "# Tokenize into words\n",
        "X['text'] = X['text'].map(lambda x: word_tokenize(x))\n",
        " \n",
        "# Remove non alphabetic tokens\n",
        "X['text'] = X['text'].map(lambda x: [word for word in x if word.isalpha()])\n",
        "\n",
        "# Filter out stop words\n",
        "stop_words = set(stopwords.words('english'))\n",
        "X['text'] = X['text'].map(lambda x: [w for w in x if not w in stop_words])\n",
        "    \n",
        "# Word Lemmatization\n",
        "lem = WordNetLemmatizer()\n",
        "X['text'] = X['text'].map(lambda x: [lem.lemmatize(word,\"v\") for word in x])\n",
        "\n",
        "# Turn lists back to string\n",
        "X['text'] = X['text'].map(lambda x: ' '.join(x))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of missing values: 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "liNeL-w5YHQO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "e998174f-da6c-4b27-903c-0b0506c5533c"
      },
      "source": [
        "X.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>zl awww bummer shoulda get david carr third day</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>upset update facebook texting might cry result...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>dive many time ball manage save rest go bound</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>whole body feel itchy like fire</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>behave mad see</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text\n",
              "0    zl awww bummer shoulda get david carr third day\n",
              "1  upset update facebook texting might cry result...\n",
              "2      dive many time ball manage save rest go bound\n",
              "3                    whole body feel itchy like fire\n",
              "4                                     behave mad see"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHySiPNEYG-v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ffa1667c-c06f-41e6-d4b8-49ec40bf93d1"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
        "print(\"TRAIN size:\", len(X_train))\n",
        "print(\"TEST size:\", len(X_train))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TRAIN size: 1280000\n",
            "TEST size: 1280000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hzxfC4hHYuN1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# WORD2VEC \n",
        "W2V_SIZE = 300\n",
        "W2V_WINDOW = 7\n",
        "W2V_EPOCH = 32\n",
        "W2V_MIN_COUNT = 10\n",
        "\n",
        "documents = [_text.split() for _text in X_train.text] \n",
        "w2v_model = gensim.models.word2vec.Word2Vec(size=W2V_SIZE, \n",
        "                                            window=W2V_WINDOW, \n",
        "                                            min_count=W2V_MIN_COUNT, \n",
        "                                            workers=8)\n",
        "w2v_model.build_vocab(documents)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-NcaEXbYuMT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bb6c17e2-7d02-4368-8e92-f118193b6317"
      },
      "source": [
        "words = w2v_model.wv.vocab.keys()\n",
        "vocab_size = len(words)\n",
        "print(\"Vocab size\", vocab_size)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocab size 25276\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FV_YXOoouViN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "25e74ed1-0f3a-4a73-fd43-5dcd73006bdd"
      },
      "source": [
        "# Train Word Embeddings\n",
        "w2v_model.train(documents, total_examples=len(documents), epochs=W2V_EPOCH)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(251358669, 289225504)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXOzYOpMY4Ca",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "outputId": "5bd80b1b-13b1-43e1-df5f-d002dfabca5b"
      },
      "source": [
        "#Test word embeddings\n",
        "w2v_model.most_similar(\"hate\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('suck', 0.5265423059463501),\n",
              " ('stupid', 0.5094816088676453),\n",
              " ('dislike', 0.47670620679855347),\n",
              " ('hat', 0.4749813973903656),\n",
              " ('despise', 0.4645768404006958),\n",
              " ('ugh', 0.4546579122543335),\n",
              " ('fuck', 0.4163169860839844),\n",
              " ('annoy', 0.3941269814968109),\n",
              " ('fml', 0.39114701747894287),\n",
              " ('horrible', 0.38840723037719727)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "viu6wTKSY36o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "a36ae78d-e184-4353-db1e-054c3373faf7"
      },
      "source": [
        "# Max number of words in each complaint.\n",
        "MAX_SEQUENCE_LENGTH = 300\n",
        "# This is fixed.\n",
        "EMBEDDING_DIM = 300\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(X_train.text)\n",
        "word_index = tokenizer.word_index\n",
        "vocab_size = len(word_index)\n",
        "print('Found %s unique tokens.' % len(word_index))\n",
        "\n",
        "# Convert the data to padded sequences\n",
        "X_train_padded = tokenizer.texts_to_sequences(X_train.text)\n",
        "X_train_padded = pad_sequences(X_train_padded, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "print('Shape of data tensor:', X_train_padded.shape)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 232838 unique tokens.\n",
            "Shape of data tensor: (1280000, 300)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tP7UzqdKY33J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# saving\n",
        "import pickle\n",
        "with open('tokenizer.pickle', 'wb') as handle:\n",
        "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPQ21bg2ZJQ3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4c59a5ec-1bb9-4fd8-8340-fbc988fb22aa"
      },
      "source": [
        "# Embedding matrix for the embedding layer\n",
        "embedding_matrix = np.zeros((vocab_size+1, W2V_SIZE))\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    if word in w2v_model.wv:\n",
        "        embedding_matrix[i] = w2v_model.wv[word]\n",
        "print(embedding_matrix.shape)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(232839, 300)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTCEC4NoZI9C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        },
        "outputId": "aa543ec0-6383-44ac-b4e8-1c70f0c83a28"
      },
      "source": [
        "# Build Model \n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size+1, W2V_SIZE, weights=[embedding_matrix], input_length=MAX_SEQUENCE_LENGTH, trainable=False))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 300, 300)          69851700  \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 300, 300)          0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 100)               160400    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 70,012,201\n",
            "Trainable params: 160,501\n",
            "Non-trainable params: 69,851,700\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8aDHAQouZUW3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "97ebe808-728c-436e-c285-0ae81b2feb48"
      },
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=\"adam\",\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DD75yElsZUAY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 632
        },
        "outputId": "6bc09b6d-b759-4390-98e2-62623eefea5b"
      },
      "source": [
        "# Training \n",
        "callbacks = [ ReduceLROnPlateau(monitor='val_loss', patience=5, cooldown=0),\n",
        "              EarlyStopping(monitor='val_acc', min_delta=1e-4, patience=5)]\n",
        "\n",
        "BATCH_SIZE = 1024\n",
        "history = model.fit(X_train_padded, y_train,\n",
        "                    batch_size=512,\n",
        "                    epochs=15,\n",
        "                    validation_split=0.1,\n",
        "                    verbose=1,\n",
        "                    callbacks=callbacks)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "Train on 1152000 samples, validate on 128000 samples\n",
            "Epoch 1/15\n",
            "1152000/1152000 [==============================] - 1049s 911us/step - loss: 0.5108 - acc: 0.7458 - val_loss: 0.4718 - val_acc: 0.7734\n",
            "Epoch 2/15\n",
            "1152000/1152000 [==============================] - 1032s 896us/step - loss: 0.4974 - acc: 0.7554 - val_loss: 0.4692 - val_acc: 0.7745\n",
            "Epoch 3/15\n",
            "1152000/1152000 [==============================] - 1030s 894us/step - loss: 0.4880 - acc: 0.7616 - val_loss: 0.4663 - val_acc: 0.7772\n",
            "Epoch 4/15\n",
            "1152000/1152000 [==============================] - 1024s 889us/step - loss: 0.4839 - acc: 0.7638 - val_loss: 0.4641 - val_acc: 0.7783\n",
            "Epoch 5/15\n",
            "1152000/1152000 [==============================] - 1023s 888us/step - loss: 0.4805 - acc: 0.7660 - val_loss: 0.4636 - val_acc: 0.7794\n",
            "Epoch 6/15\n",
            "1152000/1152000 [==============================] - 1025s 890us/step - loss: 0.4783 - acc: 0.7673 - val_loss: 0.4604 - val_acc: 0.7793\n",
            "Epoch 7/15\n",
            "1152000/1152000 [==============================] - 1027s 891us/step - loss: 0.4768 - acc: 0.7685 - val_loss: 0.4613 - val_acc: 0.7802\n",
            "Epoch 8/15\n",
            "1152000/1152000 [==============================] - 1024s 889us/step - loss: 0.4749 - acc: 0.7693 - val_loss: 0.4593 - val_acc: 0.7815\n",
            "Epoch 9/15\n",
            "1152000/1152000 [==============================] - 1025s 890us/step - loss: 0.4742 - acc: 0.7702 - val_loss: 0.4578 - val_acc: 0.7824\n",
            "Epoch 10/15\n",
            "1152000/1152000 [==============================] - 1033s 897us/step - loss: 0.4734 - acc: 0.7707 - val_loss: 0.4572 - val_acc: 0.7823\n",
            "Epoch 11/15\n",
            "1152000/1152000 [==============================] - 1031s 895us/step - loss: 0.4724 - acc: 0.7710 - val_loss: 0.4574 - val_acc: 0.7827\n",
            "Epoch 12/15\n",
            "1152000/1152000 [==============================] - 1037s 900us/step - loss: 0.4715 - acc: 0.7717 - val_loss: 0.4563 - val_acc: 0.7824\n",
            "Epoch 13/15\n",
            "1152000/1152000 [==============================] - 1031s 895us/step - loss: 0.4712 - acc: 0.7720 - val_loss: 0.4550 - val_acc: 0.7830\n",
            "Epoch 14/15\n",
            "1152000/1152000 [==============================] - 1036s 899us/step - loss: 0.4737 - acc: 0.7708 - val_loss: 0.4585 - val_acc: 0.7817\n",
            "Epoch 15/15\n",
            "1152000/1152000 [==============================] - 1039s 902us/step - loss: 0.4728 - acc: 0.7709 - val_loss: 0.4551 - val_acc: 0.7832\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcEzBzuFZm9c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('sentiment_analysis_model.h5')"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8TF-AN0wZmvI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load Model\n",
        "from keras.models import load_model\n",
        "model = load_model('sentiment_analysis_model.h5')"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcRsm1lx4GNX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "f0b78d9d-450b-4e6c-9e73-b88422e2cd94"
      },
      "source": [
        "# Evaluation\n",
        "X_test_padded = tokenizer.texts_to_sequences(X_test.text)\n",
        "X_test_padded = pad_sequences(X_test_padded, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "score = model.evaluate(X_test_padded, y_test, batch_size=512)\n",
        "print(\"ACCURACY:\",score[1])\n",
        "print(\"LOSS:\",score[0])\n",
        "\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "320000/320000 [==============================] - 101s 317us/step\n",
            "ACCURACY: 0.78459375\n",
            "LOSS: 0.45382808842658995\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_eE75t14F72",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(text, include_neutral=True):\n",
        "    # Tokenize text\n",
        "    x_test = pad_sequences(tokenizer.texts_to_sequences([text]), maxlen=MAX_SEQUENCE_LENGTH)\n",
        "    # Predict\n",
        "    score = model.predict([x_test])[0]\n",
        "    if(score >=0.4 and score<=0.6):\n",
        "        label = \"Neutral\"\n",
        "    if(score <=0.4):\n",
        "        label = \"Negative\"\n",
        "    if(score >=0.6):\n",
        "        label = \"Positive\"\n",
        "\n",
        "    return {\"label\" : label,\n",
        "        \"score\": float(score)}"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJEMINpV5a4S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "be4206bb-ff22-4d50-b385-45382a83307c"
      },
      "source": [
        "predict(\"It is a good product\")"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'label': 'Positive', 'score': 0.9039218425750732}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGgG8DJd5iah",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4b083d54-557a-46d4-961f-1cc17af55c5d"
      },
      "source": [
        "predict(\"What the hell is this\")"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'label': 'Negative', 'score': 0.3068188726902008}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzSbA4kd5own",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}